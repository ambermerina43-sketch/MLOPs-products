{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdsBRxPjUIlXJ/dvW4Vo3b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambermerina43-sketch/MLOPs-products/blob/main/Textrecognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L0jtpcsThVZg",
        "outputId": "55321d27-c8cf-46d1-f190-9a24d899b735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PART 1: Installing Required Libraries\n",
            "================================================================================\n",
            "Installing packages...\n",
            "‚úì Installed torch\n",
            "‚úì Installed torchvision\n",
            "‚úì Installed matplotlib\n",
            "‚úì Installed numpy\n",
            "‚úì Installed wandb\n",
            "‚úì Installed tqdm\n",
            "\n",
            "‚úì All packages installed!\n",
            "\n",
            "================================================================================\n",
            "PART 2: Importing Libraries\n",
            "================================================================================\n",
            "‚úì PyTorch version: 2.9.0+cu126\n",
            "‚úì CUDA available: True\n",
            "‚úì GPU: Tesla T4\n",
            "\n",
            "================================================================================\n",
            "PART 3: Setting Up Computing Device\n",
            "================================================================================\n",
            "‚úì Using device: cuda\n",
            "\n",
            "================================================================================\n",
            "PART 3.5: Creating Output Directory\n",
            "================================================================================\n",
            "‚úì Created output directory: /mnt/user-data/outputs\n",
            "\n",
            "================================================================================\n",
            "PART 4: Loading MNIST Dataset\n",
            "================================================================================\n",
            "Downloading training data...\n",
            "Downloading test data...\n",
            "‚úì Training samples: 60000\n",
            "‚úì Test samples: 10000\n",
            "\n",
            "================================================================================\n",
            "PART 5: Creating Data Loaders\n",
            "================================================================================\n",
            "‚úì Batch size: 64\n",
            "‚úì Training batches: 938\n",
            "‚úì Test batches: 157\n",
            "\n",
            "================================================================================\n",
            "PART 6: Visualizing Sample Images\n",
            "================================================================================\n",
            "‚úì Sample images saved to: sample_mnist_images.png\n",
            "\n",
            "================================================================================\n",
            "PART 7: Building CNN Model\n",
            "================================================================================\n",
            "‚úì Model architecture:\n",
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "‚úì Total parameters: 421,642\n",
            "‚úì Trainable parameters: 421,642\n",
            "\n",
            "================================================================================\n",
            "PART 8: Setting Up Training\n",
            "================================================================================\n",
            "‚úì Loss function: CrossEntropyLoss\n",
            "‚úì Optimizer: Adam (learning rate = 0.001)\n",
            "‚úì Scheduler: StepLR (reduces LR every 5 epochs)\n",
            "\n",
            "================================================================================\n",
            "PART 9: Setting Up Weights & Biases\n",
            "================================================================================\n",
            "Initializing W&B...\n",
            "You may be asked to log in. Follow the prompts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true&ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mambermerina43\u001b[0m (\u001b[33mambermerina43-rmit-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260112_093148-lvpjaz9c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial/runs/lvpjaz9c' target=\"_blank\">wobbly-tree-1</a></strong> to <a href='https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial' target=\"_blank\">https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial/runs/lvpjaz9c' target=\"_blank\">https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial/runs/lvpjaz9c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì W&B initialized!\n",
            "‚úì View your results at: https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial/runs/lvpjaz9c\n",
            "\n",
            "================================================================================\n",
            "PART 10: Defining Training Function\n",
            "================================================================================\n",
            "‚úì Training function defined\n",
            "\n",
            "================================================================================\n",
            "PART 11: Defining Evaluation Function\n",
            "================================================================================\n",
            "‚úì Evaluation function defined\n",
            "\n",
            "================================================================================\n",
            "PART 12: Starting Training!\n",
            "================================================================================\n",
            "Training for 10 epochs...\n",
            "This will take about 5-10 minutes with GPU, 20-30 minutes with CPU\n",
            "\n",
            "\n",
            "============================================================\n",
            "EPOCH 1/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 50.22it/s, loss=0.2165, acc=91.63%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:03<00:00, 52.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 1 Summary:\n",
            "   Train Loss: 0.2653 | Train Acc: 91.63%\n",
            "   Test Loss:  0.0521 | Test Acc:  98.23%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "============================================================\n",
            "EPOCH 2/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:16<00:00, 56.64it/s, loss=0.0097, acc=97.22%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 81.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 2 Summary:\n",
            "   Train Loss: 0.0960 | Train Acc: 97.22%\n",
            "   Test Loss:  0.0316 | Test Acc:  98.98%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "============================================================\n",
            "EPOCH 3/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:16<00:00, 57.64it/s, loss=0.2153, acc=97.90%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 81.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 3 Summary:\n",
            "   Train Loss: 0.0700 | Train Acc: 97.90%\n",
            "   Test Loss:  0.0277 | Test Acc:  99.10%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "============================================================\n",
            "EPOCH 4/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:17<00:00, 54.27it/s, loss=0.1168, acc=98.26%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 71.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 4 Summary:\n",
            "   Train Loss: 0.0579 | Train Acc: 98.26%\n",
            "   Test Loss:  0.0243 | Test Acc:  99.14%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "============================================================\n",
            "EPOCH 5/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:16<00:00, 57.60it/s, loss=0.0039, acc=98.56%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 82.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 5 Summary:\n",
            "   Train Loss: 0.0477 | Train Acc: 98.56%\n",
            "   Test Loss:  0.0316 | Test Acc:  99.03%\n",
            "\n",
            "============================================================\n",
            "EPOCH 6/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:16<00:00, 56.43it/s, loss=0.0879, acc=99.03%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 67.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 6 Summary:\n",
            "   Train Loss: 0.0318 | Train Acc: 99.03%\n",
            "   Test Loss:  0.0215 | Test Acc:  99.38%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "============================================================\n",
            "EPOCH 7/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:17<00:00, 54.39it/s, loss=0.0195, acc=99.23%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 80.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 7 Summary:\n",
            "   Train Loss: 0.0264 | Train Acc: 99.23%\n",
            "   Test Loss:  0.0206 | Test Acc:  99.39%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "============================================================\n",
            "EPOCH 8/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:16<00:00, 57.45it/s, loss=0.0006, acc=99.27%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 81.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 8 Summary:\n",
            "   Train Loss: 0.0230 | Train Acc: 99.27%\n",
            "   Test Loss:  0.0205 | Test Acc:  99.39%\n",
            "\n",
            "============================================================\n",
            "EPOCH 9/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:17<00:00, 55.14it/s, loss=0.0020, acc=99.34%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 59.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 9 Summary:\n",
            "   Train Loss: 0.0218 | Train Acc: 99.34%\n",
            "   Test Loss:  0.0211 | Test Acc:  99.35%\n",
            "\n",
            "============================================================\n",
            "EPOCH 10/10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:16<00:00, 57.03it/s, loss=0.0779, acc=99.36%]\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 79.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Epoch 10 Summary:\n",
            "   Train Loss: 0.0213 | Train Acc: 99.36%\n",
            "   Test Loss:  0.0204 | Test Acc:  99.43%\n",
            "   ‚úì New best accuracy! Model saved.\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETE!\n",
            "================================================================================\n",
            "‚úì Best test accuracy: 99.43%\n",
            "\n",
            "================================================================================\n",
            "PART 13: Creating Visualizations\n",
            "================================================================================\n",
            "‚úì Training history plot saved\n",
            "================================================================================\n",
            "PART 14: Visualizing Model Predictions\n",
            "================================================================================\n",
            "‚úì Predictions visualization saved\n",
            "================================================================================\n",
            "PART 15: Creating Confusion Matrix\n",
            "================================================================================\n",
            "‚úì Confusion matrix saved\n",
            "================================================================================\n",
            "PART 16: Saving Model\n",
            "================================================================================\n",
            "‚úì Model checkpoint saved to: final_model_checkpoint.pth\n",
            "\n",
            "================================================================================\n",
            "PART 17: Finalizing Weights & Biases\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>batch_loss</td><td>‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>test_accuracy</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>test_loss</td><td>‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train_accuracy</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>99.36355</td></tr><tr><td>batch_loss</td><td>0.0107</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>test_accuracy</td><td>99.43</td></tr><tr><td>test_loss</td><td>0.02044</td></tr><tr><td>train_accuracy</td><td>99.35833</td></tr><tr><td>train_loss</td><td>0.02129</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wobbly-tree-1</strong> at: <a href='https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial/runs/lvpjaz9c' target=\"_blank\">https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial/runs/lvpjaz9c</a><br> View project at: <a href='https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial' target=\"_blank\">https://wandb.ai/ambermerina43-rmit-university/mnist-cnn-tutorial</a><br>Synced 5 W&B file(s), 4 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260112_093148-lvpjaz9c/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì W&B session closed\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üéâ ALL DONE! üéâ\n",
            "================================================================================\n",
            "\n",
            "üìä RESULTS SUMMARY:\n",
            "   ‚Ä¢ Final Test Accuracy: 99.43%\n",
            "   ‚Ä¢ Total Epochs: 10\n",
            "   ‚Ä¢ Total Parameters: 421,642\n",
            "\n",
            "üìÅ FILES CREATED:\n",
            "   ‚Ä¢ sample_mnist_images.png - Sample training images\n",
            "   ‚Ä¢ training_history.png - Loss and accuracy curves\n",
            "   ‚Ä¢ predictions.png - Model predictions visualization\n",
            "   ‚Ä¢ confusion_matrix.png - Confusion matrix\n",
            "   ‚Ä¢ best_model.pth - Best model weights\n",
            "   ‚Ä¢ final_model_checkpoint.pth - Complete checkpoint\n",
            "\n",
            "üåê VIEW YOUR RESULTS:\n",
            "   ‚Ä¢ Weights & Biases Dashboard: N/A\n",
            "\n",
            "================================================================================\n",
            "Thank you for training with this guide!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "COMPLETE MNIST TRAINING GUIDE\n",
        "==============================\n",
        "This script does EVERYTHING you need:\n",
        "1. Install dependencies\n",
        "2. Load MNIST dataset\n",
        "3. Build a CNN model\n",
        "4. Train the model\n",
        "5. Visualize results with Weights & Biases\n",
        "\n",
        "Each section is clearly explained!\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# PART 1: INSTALL ALL REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 1: Installing Required Libraries\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# What this does: Installs all the Python packages we need\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a Python package using pip\"\"\"\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "# List of required packages\n",
        "packages = [\n",
        "    \"torch\",           # PyTorch - for building neural networks\n",
        "    \"torchvision\",     # Contains MNIST dataset\n",
        "    \"matplotlib\",      # For creating plots and visualizations\n",
        "    \"numpy\",           # For numerical operations\n",
        "    \"wandb\",           # Weights & Biases - for experiment tracking\n",
        "    \"tqdm\",            # Progress bars\n",
        "]\n",
        "\n",
        "print(\"Installing packages...\")\n",
        "for package in packages:\n",
        "    try:\n",
        "        install_package(package)\n",
        "        print(f\"‚úì Installed {package}\")\n",
        "    except:\n",
        "        print(f\"‚úó Failed to install {package}\")\n",
        "\n",
        "print(\"\\n‚úì All packages installed!\\n\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: IMPORT LIBRARIES\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 2: Importing Libraries\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import os # Import os module for directory operations\n",
        "\n",
        "print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"! Running on CPU (will be slower)\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: SET UP DEVICE (GPU or CPU)\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 3: Setting Up Computing Device\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# What this does: Checks if GPU is available, otherwise uses CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úì Using device: {device}\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3.5: CREATE OUTPUTS DIRECTORY\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 3.5: Creating Output Directory\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create the directory for saving outputs if it doesn't exist\n",
        "output_dir = '/mnt/user-data/outputs'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"‚úì Created output directory: {output_dir}\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# PART 4: DOWNLOAD AND PREPARE MNIST DATASET\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 4: Loading MNIST Dataset\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# What is MNIST?\n",
        "# - Collection of 70,000 handwritten digits (0-9)\n",
        "# - 60,000 for training, 10,000 for testing\n",
        "# - Each image is 28x28 pixels, grayscale\n",
        "\n",
        "# Transform: Converts images to tensors and normalizes them\n",
        "# Normalization makes training more stable\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "# Download training data\n",
        "print(\"Downloading training data...\")\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',      # Where to save the data\n",
        "    train=True,         # Get training set\n",
        "    download=True,      # Download if not already present\n",
        "    transform=transform # Apply transformations\n",
        ")\n",
        "\n",
        "# Download test data\n",
        "print(\"Downloading test data...\")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,        # Get test set\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"‚úì Training samples: {len(train_dataset)}\")\n",
        "print(f\"‚úì Test samples: {len(test_dataset)}\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 5: CREATE DATA LOADERS\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 5: Creating Data Loaders\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# What is a DataLoader?\n",
        "# - Batches data into groups (e.g., 64 images at a time)\n",
        "# - Shuffles data for better training\n",
        "# - Handles loading data efficiently\n",
        "\n",
        "batch_size = 64  # Process 64 images at a time\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,       # Shuffle for randomness\n",
        "    num_workers=2       # Use 2 processes to load data faster\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"‚úì Batch size: {batch_size}\")\n",
        "print(f\"‚úì Training batches: {len(train_loader)}\")\n",
        "print(f\"‚úì Test batches: {len(test_loader)}\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 6: VISUALIZE SAMPLE DATA\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 6: Visualizing Sample Images\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def show_sample_images(dataset, num_samples=10):\n",
        "    \"\"\"Display sample images from the dataset\"\"\"\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        image, label = dataset[i]\n",
        "\n",
        "        # Convert tensor to numpy for visualization\n",
        "        image = image.squeeze().numpy()\n",
        "\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "        axes[i].set_title(f'Label: {label}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/user-data/outputs/sample_mnist_images.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"‚úì Sample images saved to: sample_mnist_images.png\")\n",
        "    plt.close()\n",
        "\n",
        "show_sample_images(train_dataset)\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 7: BUILD THE CNN MODEL\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 7: Building CNN Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network for MNIST\n",
        "\n",
        "    Architecture:\n",
        "    - Conv Layer 1: Detects basic features (edges, curves)\n",
        "    - Conv Layer 2: Detects more complex patterns\n",
        "    - Fully Connected Layers: Makes final classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # CONVOLUTIONAL LAYERS\n",
        "        # Layer 1: 1 input channel (grayscale), 32 output channels\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # Reduces size by half\n",
        "\n",
        "        # Layer 2: 32 input channels, 64 output channels\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # Reduces size by half again\n",
        "\n",
        "        # FULLY CONNECTED LAYERS\n",
        "        # After 2 pooling layers: 28x28 -> 14x14 -> 7x7\n",
        "        # 64 channels √ó 7 √ó 7 = 3136 features\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Hidden layer\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)  # Prevents overfitting\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output layer (10 digits: 0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: how data flows through the network\n",
        "        Input: x is a batch of images [batch_size, 1, 28, 28]\n",
        "        Output: predictions for each of 10 classes\n",
        "        \"\"\"\n",
        "        # Convolutional layers\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))  # -> [batch, 32, 14, 14]\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))  # -> [batch, 64, 7, 7]\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = x.view(-1, 64 * 7 * 7)  # -> [batch, 3136]\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.relu3(self.fc1(x))  # -> [batch, 128]\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)  # -> [batch, 10]\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create the model and move it to GPU/CPU\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"‚úì Model architecture:\")\n",
        "print(model)\n",
        "print(f\"\\n‚úì Total parameters: {total_params:,}\")\n",
        "print(f\"‚úì Trainable parameters: {trainable_params:,}\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 8: SET UP TRAINING COMPONENTS\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 8: Setting Up Training\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Loss function: Measures how wrong the predictions are\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer: Updates model weights to reduce loss\n",
        "# Adam is a popular, efficient optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Learning rate scheduler: Reduces learning rate over time\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "print(\"‚úì Loss function: CrossEntropyLoss\")\n",
        "print(\"‚úì Optimizer: Adam (learning rate = 0.001)\")\n",
        "print(\"‚úì Scheduler: StepLR (reduces LR every 5 epochs)\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 9: INITIALIZE WEIGHTS & BIASES (W&B)\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 9: Setting Up Weights & Biases\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# What is Weights & Biases?\n",
        "# - Tool for tracking experiments\n",
        "# - Visualizes loss, accuracy, and more\n",
        "# - Creates beautiful dashboards\n",
        "\n",
        "print(\"Initializing W&B...\")\n",
        "print(\"You may be asked to log in. Follow the prompts.\")\n",
        "\n",
        "wandb.init(\n",
        "    project=\"mnist-cnn-tutorial\",  # Project name\n",
        "    config={                        # Configuration to track\n",
        "        \"architecture\": \"CNN\",\n",
        "        \"dataset\": \"MNIST\",\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": 10,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"optimizer\": \"Adam\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Watch the model (tracks gradients and parameters)\n",
        "wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
        "\n",
        "print(\"‚úì W&B initialized!\")\n",
        "print(f\"‚úì View your results at: {wandb.run.get_url()}\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 10: TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 10: Defining Training Function\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Average loss for this epoch\n",
        "        accuracy: Training accuracy\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Progress bar\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(pbar):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # TRAINING STEPS:\n",
        "\n",
        "        # 1. Zero the gradients from previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Forward pass: get predictions\n",
        "        outputs = model(images)\n",
        "\n",
        "        # 3. Calculate loss: how wrong are the predictions?\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 4. Backward pass: calculate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Update progress bar\n",
        "        accuracy = 100. * correct / total\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{accuracy:.2f}%'\n",
        "        })\n",
        "\n",
        "        # Log to W&B every 100 batches\n",
        "        if batch_idx % 100 == 0:\n",
        "            wandb.log({\n",
        "                \"batch_loss\": loss.item(),\n",
        "                \"batch_accuracy\": accuracy\n",
        "            })\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    final_accuracy = 100. * correct / total\n",
        "\n",
        "    return avg_loss, final_accuracy\n",
        "\n",
        "print(\"‚úì Training function defined\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 11: TESTING/EVALUATION FUNCTION\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 11: Defining Evaluation Function\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on test data\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Average loss on test set\n",
        "        accuracy: Test accuracy\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Don't track gradients during evaluation (saves memory)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass only\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Track statistics\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "print(\"‚úì Evaluation function defined\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 12: MAIN TRAINING LOOP\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 12: Starting Training!\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "print(f\"Training for {num_epochs} epochs...\")\n",
        "print(\"This will take about 5-10 minutes with GPU, 20-30 minutes with CPU\")\n",
        "print()\n",
        "\n",
        "best_accuracy = 0.0\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EPOCH {epoch}/{num_epochs}\")\n",
        "    print('='*60)\n",
        "\n",
        "    # Train for one epoch\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, criterion, optimizer, device, epoch\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Log to W&B\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_accuracy\": test_acc,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\nüìä Epoch {epoch} Summary:\")\n",
        "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"   Test Loss:  {test_loss:.4f} | Test Acc:  {test_acc:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        torch.save(model.state_dict(), '/mnt/user-data/outputs/best_model.pth')\n",
        "        print(f\"   ‚úì New best accuracy! Model saved.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"‚úì Best test accuracy: {best_accuracy:.2f}%\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 13: VISUALIZE TRAINING RESULTS\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 13: Creating Visualizations\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def plot_training_history(train_losses, test_losses, train_accs, test_accs):\n",
        "    \"\"\"Plot loss and accuracy curves\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    # Plot losses\n",
        "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
        "    ax1.plot(epochs, test_losses, 'r-', label='Test Loss', linewidth=2)\n",
        "    ax1.set_xlabel('Epoch', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.set_title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot accuracies\n",
        "    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy', linewidth=2)\n",
        "    ax2.plot(epochs, test_accs, 'r-', label='Test Accuracy', linewidth=2)\n",
        "    ax2.set_xlabel('Epoch', fontsize=12)\n",
        "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax2.set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/user-data/outputs/training_history.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"‚úì Training history plot saved\")\n",
        "    plt.close()\n",
        "\n",
        "plot_training_history(train_losses, test_losses, train_accuracies, test_accuracies)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 14: VISUALIZE PREDICTIONS\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 14: Visualizing Model Predictions\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def visualize_predictions(model, test_loader, device, num_images=20):\n",
        "    \"\"\"Show model predictions on test images\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get a batch of test images\n",
        "    images, labels = next(iter(test_loader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predictions = outputs.max(1)\n",
        "\n",
        "    # Move to CPU for plotting\n",
        "    images = images.cpu()\n",
        "    labels = labels.cpu()\n",
        "    predictions = predictions.cpu()\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(num_images):\n",
        "        image = images[i].squeeze().numpy()\n",
        "        true_label = labels[i].item()\n",
        "        pred_label = predictions[i].item()\n",
        "\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "\n",
        "        # Color: green if correct, red if wrong\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}',\n",
        "                         color=color, fontweight='bold')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/user-data/outputs/predictions.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"‚úì Predictions visualization saved\")\n",
        "    plt.close()\n",
        "\n",
        "visualize_predictions(model, test_loader, device)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 15: CONFUSION MATRIX\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 15: Creating Confusion Matrix\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def create_confusion_matrix(model, test_loader, device):\n",
        "    \"\"\"Create confusion matrix showing which digits are confused\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predictions = outputs.max(1)\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Create confusion matrix\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.xlabel('Predicted', fontsize=12)\n",
        "    plt.ylabel('True', fontsize=12)\n",
        "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/user-data/outputs/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"‚úì Confusion matrix saved\")\n",
        "    plt.close()\n",
        "\n",
        "# Install sklearn if needed\n",
        "try:\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "except:\n",
        "    install_package(\"scikit-learn\")\n",
        "    install_package(\"seaborn\")\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "\n",
        "create_confusion_matrix(model, test_loader, device)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 16: SAVE FINAL MODEL\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 16: Saving Model\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save complete model\n",
        "torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'best_accuracy': best_accuracy,\n",
        "}, '/mnt/user-data/outputs/final_model_checkpoint.pth')\n",
        "\n",
        "print(\"‚úì Model checkpoint saved to: final_model_checkpoint.pth\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 17: FINISH W&B\n",
        "# =============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"PART 17: Finalizing Weights & Biases\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Log final images to W&B\n",
        "wandb.log({\n",
        "    \"sample_images\": wandb.Image('/mnt/user-data/outputs/sample_mnist_images.png'),\n",
        "    \"training_history\": wandb.Image('/mnt/user-data/outputs/training_history.png'),\n",
        "    \"predictions\": wandb.Image('/mnt/user-data/outputs/predictions.png'),\n",
        "    \"confusion_matrix\": wandb.Image('/mnt/user-data/outputs/confusion_matrix.png')\n",
        "})\n",
        "\n",
        "wandb.finish()\n",
        "print(\"‚úì W&B session closed\")\n",
        "print()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# FINAL SUMMARY\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéâ ALL DONE! üéâ\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüìä RESULTS SUMMARY:\")\n",
        "print(f\"   ‚Ä¢ Final Test Accuracy: {best_accuracy:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Total Epochs: {num_epochs}\")\n",
        "print(f\"   ‚Ä¢ Total Parameters: {total_params:,}\")\n",
        "print(\"\\nüìÅ FILES CREATED:\")\n",
        "print(\"   ‚Ä¢ sample_mnist_images.png - Sample training images\")\n",
        "print(\"   ‚Ä¢ training_history.png - Loss and accuracy curves\")\n",
        "print(\"   ‚Ä¢ predictions.png - Model predictions visualization\")\n",
        "print(\"   ‚Ä¢ confusion_matrix.png - Confusion matrix\")\n",
        "print(\"   ‚Ä¢ best_model.pth - Best model weights\")\n",
        "print(\"   ‚Ä¢ final_model_checkpoint.pth - Complete checkpoint\")\n",
        "print(\"\\nüåê VIEW YOUR RESULTS:\")\n",
        "print(f\"   ‚Ä¢ Weights & Biases Dashboard: {wandb.run.get_url() if wandb.run else 'N/A'}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Thank you for training with this guide!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "INTERACTIVE HANDWRITTEN DIGIT RECOGNIZER APP\n",
        "============================================\n",
        "Draw a digit and watch the AI recognize it in real-time!\n",
        "\n",
        "This app uses Gradio to create a web interface where you can:\n",
        "1. Draw digits with your mouse/finger\n",
        "2. See what the model predicts\n",
        "3. View confidence scores for all digits\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# PART 1: INSTALL AND IMPORT LIBRARIES\n",
        "# =============================================================================\n",
        "print(\"Installing Gradio for the web interface...\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "# Install required packages\n",
        "try:\n",
        "    import gradio as gr\n",
        "except:\n",
        "    install_package(\"gradio\")\n",
        "    import gradio as gr\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"‚úì All libraries loaded!\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: DEFINE THE CNN MODEL (SAME AS TRAINING)\n",
        "# =============================================================================\n",
        "print(\"Setting up the model...\")\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Same CNN architecture used for training\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: LOAD THE TRAINED MODEL\n",
        "# =============================================================================\n",
        "print(\"Loading trained model...\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Try to load the trained model\n",
        "try:\n",
        "    # Load the best model weights\n",
        "    model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
        "    print(\"‚úì Loaded trained model from 'best_model.pth'\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö† No trained model found!\")\n",
        "    print(\"Please run the training script first to create 'best_model.pth'\")\n",
        "    print(\"Or the model will use random weights (won't work well)\")\n",
        "\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 4: IMAGE PREPROCESSING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Convert drawn image to format expected by model\n",
        "\n",
        "    Args:\n",
        "        image: PIL Image or numpy array from Gradio\n",
        "\n",
        "    Returns:\n",
        "        tensor: Preprocessed image tensor\n",
        "    \"\"\"\n",
        "    # Convert to PIL Image if numpy array\n",
        "    if isinstance(image, np.ndarray):\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "    # Convert to grayscale\n",
        "    image = image.convert('L')\n",
        "\n",
        "    # Resize to 28x28 (MNIST size)\n",
        "    image = image.resize((28, 28), Image.LANCZOS)\n",
        "\n",
        "    # Invert colors (MNIST has white digits on black background)\n",
        "    # Drawing apps usually have black on white\n",
        "    image = Image.eval(image, lambda x: 255 - x)\n",
        "\n",
        "    # Convert to tensor and normalize\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    tensor = transform(image)\n",
        "\n",
        "    # Add batch dimension\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 5: PREDICTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def predict_digit(image):\n",
        "    \"\"\"\n",
        "    Predict the digit from a drawn image\n",
        "\n",
        "    Args:\n",
        "        image: Image from Gradio drawing canvas\n",
        "\n",
        "    Returns:\n",
        "        dict: Confidence scores for each digit (0-9)\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return {str(i): 0.0 for i in range(10)}\n",
        "\n",
        "    # Preprocess the image\n",
        "    tensor = preprocess_image(image).to(device)\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor)\n",
        "        # Convert to probabilities using softmax\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "        probabilities = probabilities.cpu().numpy()[0]\n",
        "\n",
        "    # Create dictionary of digit: confidence\n",
        "    predictions = {str(i): float(probabilities[i]) for i in range(10)}\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 6: CREATE GRADIO INTERFACE\n",
        "# =============================================================================\n",
        "print(\"Creating web interface...\")\n",
        "\n",
        "# Custom CSS for better styling\n",
        "custom_css = \"\"\"\n",
        "#title {\n",
        "    text-align: center;\n",
        "    font-size: 2.5em;\n",
        "    font-weight: bold;\n",
        "    color: #2563eb;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "#description {\n",
        "    text-align: center;\n",
        "    font-size: 1.2em;\n",
        "    color: #64748b;\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "#draw-canvas {\n",
        "    border: 3px solid #2563eb;\n",
        "    border-radius: 10px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the interface\n",
        "with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "    # Title and description\n",
        "    gr.Markdown(\"# üé® Handwritten Digit Recognizer\", elem_id=\"title\")\n",
        "    gr.Markdown(\n",
        "        \"Draw a digit (0-9) in the canvas below and watch the AI predict it in real-time!\",\n",
        "        elem_id=\"description\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left column: Drawing canvas\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### ‚úèÔ∏è Draw Here\")\n",
        "            canvas = gr.Sketchpad(\n",
        "                label=\"Draw a digit\",\n",
        "                type=\"pil\",\n",
        "                image_mode=\"RGB\",\n",
        "                canvas_size=(280, 280),\n",
        "                brush=gr.Brush(\n",
        "                    default_size=20,\n",
        "                    colors=[\"#000000\"],\n",
        "                    default_color=\"#000000\"\n",
        "                ),\n",
        "                elem_id=\"draw-canvas\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\"üóëÔ∏è Clear\", variant=\"secondary\")\n",
        "                predict_btn = gr.Button(\"üîÆ Predict\", variant=\"primary\")\n",
        "\n",
        "        # Right column: Results\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### üìä Prediction Results\")\n",
        "\n",
        "            # Confidence bar chart\n",
        "            confidence_plot = gr.Label(\n",
        "                label=\"Confidence Scores\",\n",
        "                num_top_classes=10\n",
        "            )\n",
        "\n",
        "            # Show preprocessed image (what the model sees)\n",
        "            with gr.Accordion(\"üîç What the Model Sees\", open=False):\n",
        "                processed_image = gr.Image(\n",
        "                    label=\"Preprocessed Image (28√ó28)\",\n",
        "                    type=\"pil\"\n",
        "                )\n",
        "\n",
        "    # Instructions\n",
        "    with gr.Accordion(\"üìñ How to Use\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "        **Instructions:**\n",
        "        1. Draw a digit (0-9) in the canvas on the left\n",
        "        2. Click \"Predict\" or just wait (auto-predicts)\n",
        "        3. See the results on the right\n",
        "        4. Click \"Clear\" to try another digit\n",
        "\n",
        "        **Tips for Best Results:**\n",
        "        - Draw digits large and centered\n",
        "        - Use clear, simple strokes\n",
        "        - Try to match MNIST style (like handwritten on paper)\n",
        "        - If prediction is wrong, try drawing clearer\n",
        "\n",
        "        **What You'll See:**\n",
        "        - **Confidence Scores**: How sure the model is for each digit\n",
        "        - **Preprocessed Image**: The 28√ó28 image the model actually sees\n",
        "        \"\"\")\n",
        "\n",
        "    # Function to show preprocessed image\n",
        "    def show_preprocessing(image):\n",
        "        \"\"\"Show what the model actually sees\"\"\"\n",
        "        if image is None:\n",
        "            return None\n",
        "\n",
        "        tensor = preprocess_image(image)\n",
        "\n",
        "        # Convert back to PIL for display\n",
        "        img_array = tensor.squeeze().cpu().numpy()\n",
        "        # Denormalize\n",
        "        img_array = (img_array * 0.5) + 0.5\n",
        "        img_array = (img_array * 255).astype(np.uint8)\n",
        "\n",
        "        return Image.fromarray(img_array, mode='L')\n",
        "\n",
        "    # Prediction function that returns both results and preprocessed image\n",
        "    def predict_and_show(image):\n",
        "        \"\"\"Predict and show preprocessed image\"\"\"\n",
        "        predictions = predict_digit(image)\n",
        "        preprocessed = show_preprocessing(image)\n",
        "        return predictions, preprocessed\n",
        "\n",
        "    # Event handlers\n",
        "    predict_btn.click(\n",
        "        fn=predict_and_show,\n",
        "        inputs=canvas,\n",
        "        outputs=[confidence_plot, processed_image]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=lambda: (None, None, {str(i): 0.0 for i in range(10)}),\n",
        "        inputs=None,\n",
        "        outputs=[canvas, processed_image, confidence_plot]\n",
        "    )\n",
        "\n",
        "    # Auto-predict on change (with debounce)\n",
        "    canvas.change(\n",
        "        fn=predict_and_show,\n",
        "        inputs=canvas,\n",
        "        outputs=[confidence_plot, processed_image]\n",
        "    )\n",
        "\n",
        "    # Examples section\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"### üí° Example Digits\")\n",
        "    gr.Markdown(\"Try drawing digits that look like these MNIST samples:\")\n",
        "\n",
        "    # Could add example images here if you have them\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 7: LAUNCH THE APP\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ LAUNCHING APP!\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nThe app will open in a new browser window/tab.\")\n",
        "print(\"You can also access it via the public URL shown below.\")\n",
        "print(\"\\nTo stop the app, press Ctrl+C or interrupt the cell.\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(\n",
        "    share=True,        # Creates a public URL you can share\n",
        "    debug=False,       # Set to True for debugging\n",
        "    show_error=True    # Show errors in the interface\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oPhBJDZnmjJ1",
        "outputId": "5a37f09f-af24-4ab2-92de-f8e18f83317a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Gradio for the web interface...\n",
            "‚úì All libraries loaded!\n",
            "Setting up the model...\n",
            "Loading trained model...\n",
            "‚ö† No trained model found!\n",
            "Please run the training script first to create 'best_model.pth'\n",
            "Or the model will use random weights (won't work well)\n",
            "Creating web interface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3138579640.py:200: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:\n",
            "/tmp/ipython-input-3138579640.py:200: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ LAUNCHING APP!\n",
            "================================================================================\n",
            "\n",
            "The app will open in a new browser window/tab.\n",
            "You can also access it via the public URL shown below.\n",
            "\n",
            "To stop the app, press Ctrl+C or interrupt the cell.\n",
            "================================================================================\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a4e631f28e7a81f849.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a4e631f28e7a81f849.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}